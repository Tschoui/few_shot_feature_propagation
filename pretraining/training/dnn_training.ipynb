{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1312bcf3-f32d-4679-8366-34d8d86a2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from dnn import DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7483b687-ae95-4dfe-bfe1-1421f9b7e88e",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e24999-1397-4266-8c27-156a09386268",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_tox21_features_train_val_test = np.load('../../preprocessing/preprocessed_data/tox21_features_train_val_test.npy', allow_pickle=True).item()\n",
    "\n",
    "tox21_X_train = loaded_tox21_features_train_val_test['train']\n",
    "tox21_X_val = loaded_tox21_features_train_val_test['validation']\n",
    "tox21_X_test = loaded_tox21_features_train_val_test['test']\n",
    "\n",
    "loaded_tox21_labels_train_val_test = np.load('../../preprocessing/preprocessed_data/tox21_labels_train_val_test.npy', allow_pickle=True).item()\n",
    "\n",
    "tox21_y_train = loaded_tox21_labels_train_val_test['train']\n",
    "tox21_y_val = loaded_tox21_labels_train_val_test['validation']\n",
    "tox21_y_test = loaded_tox21_labels_train_val_test['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4fd1bb-4015-4434-91bc-093e38240104",
   "metadata": {},
   "source": [
    "**Check shapes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef072e51-3cfb-4b25-80fb-0cdf59c057d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Train/Val/Test Shapes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4698, 2248), (1566, 2248), (1567, 2248)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Features Train/Val/Test Shapes:')\n",
    "[i.shape for i in [tox21_X_train, tox21_X_val, tox21_X_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc9fb43-aab4-4113-ade2-f8c6dba520e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Train/Val/Test Shapes:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(4698, 12), (1566, 12), (1567, 12)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Labels Train/Val/Test Shapes:')\n",
    "[i.shape for i in [tox21_y_train, tox21_y_val, tox21_y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f652eb-4189-471a-8b0d-ee185c1166fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_y_train = np.where(tox21_y_train == -1, 0, tox21_y_train)\n",
    "tox21_y_val = np.where(tox21_y_val == -1, 0, tox21_y_val)\n",
    "tox21_y_test = np.where(tox21_y_test == -1, 0, tox21_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1715b60-4ba8-453e-8e59-0e2a11ed22a8",
   "metadata": {},
   "source": [
    "**Create dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea13e4f2-82f2-40f6-9e54-f47853cb0d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(X_train, y_train, X_val, y_val, X_test, y_test, batch_size=512):\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b5c74-6130-463e-9b17-f85f90d51e07",
   "metadata": {},
   "source": [
    "**Create training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695a83f9-925e-4fd4-82e5-f2d8b8a4e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validation_loop(model, dataloader_train, dataloader_val, loss_func, optimizer, num_epochs=10, device='cpu'):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for batch_X, batch_y in dataloader_train:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = loss_func(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item() * batch_X.shape[0]\n",
    "        \n",
    "        train_loss_per_epoch = total_train_loss / len(dataloader_train.dataset)\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "\n",
    "            val_outputs = []\n",
    "            val_labels = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_X, batch_y in dataloader_val:\n",
    "                    batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "                    outputs = model(batch_X)\n",
    "                    loss = loss_func(outputs, batch_y)\n",
    "\n",
    "                    total_val_loss += loss.item() * batch_X.shape[0]\n",
    "\n",
    "                    val_outputs.append(outputs.cpu())\n",
    "                    val_labels.append(batch_y.cpu())\n",
    "                \n",
    "            val_loss_per_epoch = total_val_loss / len(dataloader_val.dataset)\n",
    "            \n",
    "            val_outputs = torch.cat(val_outputs)\n",
    "            val_labels = torch.cat(val_labels)\n",
    "            \n",
    "            roc_auc_scores = []\n",
    "\n",
    "            for task in range(val_labels.shape[-1]):\n",
    "                roc_auc = roc_auc_score(val_labels[:, task], val_outputs[:, task])\n",
    "                roc_auc_scores.append(roc_auc)\n",
    "            \n",
    "            roc_auc_scores_mean = np.mean(roc_auc_scores)\n",
    "            roc_auc_scores_std = np.std(roc_auc_scores)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "                  f'Train Loss: {train_loss_per_epoch:.4f}, '\n",
    "                  f'Validation Loss: {val_loss_per_epoch:.4f}, '\n",
    "                  f'Validation AUC mean: {roc_auc_scores_mean:.4f}, '\n",
    "                  f'Validation AUC std: {roc_auc_scores_std:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c6f13-db46-48dd-89e4-11af31990c90",
   "metadata": {},
   "source": [
    "**Set hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9574ff84-c182-478e-b533-d0b61731ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'input_size': 2248,\n",
    "          'hidden_layers': [1024, 512],\n",
    "          'output_size': 12,\n",
    "          'learning_rate': 1e-3,\n",
    "          'activation_function': nn.ReLU,\n",
    "          'dropout_p': 0.25,\n",
    "          'batch_size': 512}\n",
    "\n",
    "input_size, hidden_layers, output_size, learning_rate, activation_function, dropout_p, batch_size = params.values()\n",
    "num_epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7eaec-3edc-479a-9fd4-968e79cd9c2f",
   "metadata": {},
   "source": [
    "**Model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73aff63-2890-482e-a6e4-a628c4497fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN(input_size, hidden_layers, output_size, activation_function, p=dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33e99f45-b3f3-4399-8185-f09773dfc808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (input_layer): Linear(in_features=2248, out_features=1024, bias=True)\n",
       "  (act1): ReLU()\n",
       "  (dropout1): Dropout(p=0.25, inplace=False)\n",
       "  (hidden_layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00ac1a0c-8cf3-46a3-87e4-4362267df9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2c74b2-6ff8-46e5-8043-115ad47d5c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = create_dataloaders(tox21_X_train, \n",
    "                                                           tox21_y_train, \n",
    "                                                           tox21_X_val, \n",
    "                                                           tox21_y_val, \n",
    "                                                           tox21_X_test, \n",
    "                                                           tox21_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50d734dc-f25f-46d2-b825-737df2218fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.3481, Validation Loss: 0.2298, Validation AUC mean: 0.7495, Validation AUC std: 0.0496\n",
      "Epoch 2/10, Train Loss: 0.2032, Validation Loss: 0.2028, Validation AUC mean: 0.7653, Validation AUC std: 0.0523\n",
      "Epoch 3/10, Train Loss: 0.1611, Validation Loss: 0.1973, Validation AUC mean: 0.7770, Validation AUC std: 0.0549\n",
      "Epoch 4/10, Train Loss: 0.1333, Validation Loss: 0.1902, Validation AUC mean: 0.7854, Validation AUC std: 0.0551\n",
      "Epoch 5/10, Train Loss: 0.1084, Validation Loss: 0.1958, Validation AUC mean: 0.7847, Validation AUC std: 0.0532\n",
      "Epoch 6/10, Train Loss: 0.0857, Validation Loss: 0.2119, Validation AUC mean: 0.7834, Validation AUC std: 0.0547\n",
      "Epoch 7/10, Train Loss: 0.0682, Validation Loss: 0.2260, Validation AUC mean: 0.7803, Validation AUC std: 0.0566\n",
      "Epoch 8/10, Train Loss: 0.0548, Validation Loss: 0.2481, Validation AUC mean: 0.7747, Validation AUC std: 0.0564\n",
      "Epoch 9/10, Train Loss: 0.0447, Validation Loss: 0.2721, Validation AUC mean: 0.7651, Validation AUC std: 0.0581\n",
      "Epoch 10/10, Train Loss: 0.0381, Validation Loss: 0.2930, Validation AUC mean: 0.7659, Validation AUC std: 0.0560\n"
     ]
    }
   ],
   "source": [
    "train_validation_loop(model, train_loader, val_loader, loss_func, optimizer, num_epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ffad44-1ab5-4c49-8f75-169733e1f05e",
   "metadata": {},
   "source": [
    "**Test the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8944faaf-c800-4095-a528-e1ed0e2c922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader, loss_func, device='cpu'):\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "\n",
    "    test_outputs = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "            outputs = model(batch_X)\n",
    "            loss = loss_func(outputs, batch_y)\n",
    "\n",
    "            total_test_loss += loss.item() * batch_X.shape[0]\n",
    "\n",
    "            test_outputs.append(outputs.cpu())\n",
    "            test_labels.append(batch_y.cpu())\n",
    "\n",
    "    test_loss = total_test_loss / len(test_loader.dataset)\n",
    "\n",
    "    test_outputs = torch.cat(test_outputs)\n",
    "    test_labels = torch.cat(test_labels)\n",
    "\n",
    "    roc_auc_scores = []\n",
    "\n",
    "    for task in range(test_labels.shape[-1]):\n",
    "        roc_auc = roc_auc_score(test_labels[:, task], test_outputs[:, task])\n",
    "        roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    roc_auc_scores_mean = np.mean(roc_auc_scores)\n",
    "    roc_auc_scores_std = np.std(roc_auc_scores)\n",
    "    return roc_auc_scores_mean, roc_auc_scores_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ee02a07-fc6a-4ca2-bda2-9892343c31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_scores_mean, roc_auc_scores_std = test_model(model, test_loader, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f1a8a8c-a5a5-4c7a-90db-f28aadbc6a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC mean: 0.7788, AUC std: 0.0500\n"
     ]
    }
   ],
   "source": [
    "print(f'AUC mean: {roc_auc_scores_mean:.4f}, AUC std: {roc_auc_scores_std:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
